{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df9be32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10a10995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# array normalization\n",
    "def normalize(X, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(X, order, axis))\n",
    "    l2[l2 == 0] = 1\n",
    "    return X / np.expand_dims(l2, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e30dc2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a494b0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class_0', 'class_1', 'class_2']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea666231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ecf3efb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29a42a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41311526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d5de840",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(data= np.c_[data['data'], data['target']],\n",
    "                     columns= data['feature_names'] + ['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36f1b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['target_names'] = data1['target_names'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c0c2989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  target_names  \n",
       "0                            3.92   1065.0             0  \n",
       "1                            3.40   1050.0             0  \n",
       "2                            3.17   1185.0             0  \n",
       "3                            3.45   1480.0             0  \n",
       "4                            2.93    735.0             0  \n",
       "..                            ...      ...           ...  \n",
       "173                          1.74    740.0             2  \n",
       "174                          1.56    750.0             2  \n",
       "175                          1.56    835.0             2  \n",
       "176                          1.62    840.0             2  \n",
       "177                          1.60    560.0             2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "324368ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.32644724e-02, 1.59397384e-03, 2.26512072e-03, ...,\n",
       "        9.69434383e-04, 3.65402190e-03, 9.92738094e-01],\n",
       "       [1.25128005e-02, 1.68733218e-03, 2.02859038e-03, ...,\n",
       "        9.95336401e-04, 3.22299406e-03, 9.95336401e-01],\n",
       "       [1.10630135e-02, 1.98394467e-03, 2.24454758e-03, ...,\n",
       "        8.65874158e-04, 2.66487484e-03, 9.96175609e-01],\n",
       "       ...,\n",
       "       [1.57227449e-02, 5.07108879e-03, 2.67772446e-03, ...,\n",
       "        6.99051960e-04, 1.84834078e-03, 9.89336248e-01],\n",
       "       [1.55136606e-02, 3.05090212e-03, 2.79175213e-03, ...,\n",
       "        7.06772691e-04, 1.90828627e-03, 9.89481768e-01],\n",
       "       [2.48340486e-02, 7.20591644e-03, 4.81566123e-03, ...,\n",
       "        1.07209976e-03, 2.81206495e-03, 9.84222734e-01]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input data, normalization\n",
    "x = data1.copy().astype(np.float64).drop(\"target_names\", axis=1)\n",
    "x = normalize(x.to_numpy())\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6b74615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formation of target data\n",
    "columns = ['target_names']\n",
    "y = pd.DataFrame(data1, columns=columns, dtype='int64')\n",
    "y = y.to_numpy()\n",
    "y = y.flatten()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cda73eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separation of data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ad6a011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 1, 2, 0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 2, 1, 0, 2, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 2, 1, 1, 1, 0, 1, 1, 1, 2, 2, 0, 1, 2, 2, 1, 1,\n",
       "       0, 1, 2, 2, 1, 2, 1, 1, 1, 0, 0, 2, 0, 2, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 2, 1, 1, 1, 2, 2, 1, 0, 0, 1, 2, 2, 0, 1, 2, 2, 2, 2, 1, 0,\n",
       "       1, 0, 2, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 1, 1, 1, 1,\n",
       "       1, 1, 2, 0, 1, 1, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training target\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55296ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.31805705e-02, 1.78817368e-03, 2.26886553e-03, ...,\n",
       "        1.06713590e-03, 3.84553479e-03, 9.95032127e-01],\n",
       "       [3.27814817e-02, 1.19033622e-02, 5.26676544e-03, ...,\n",
       "        1.36983137e-03, 3.14116504e-03, 9.80137963e-01],\n",
       "       [2.81319418e-02, 3.22750512e-03, 4.53224124e-03, ...,\n",
       "        2.81548319e-03, 6.27188939e-03, 9.79696591e-01],\n",
       "       ...,\n",
       "       [9.27438445e-03, 1.20605695e-03, 1.53498157e-03, ...,\n",
       "        7.73940288e-04, 1.93485072e-03, 9.97738021e-01],\n",
       "       [2.52769066e-02, 3.04757030e-03, 4.50163979e-03, ...,\n",
       "        1.91220097e-03, 4.10326459e-03, 9.85978626e-01],\n",
       "       [2.74502920e-02, 5.45001746e-03, 5.47226243e-03, ...,\n",
       "        1.77959754e-03, 7.51879960e-03, 9.74329652e-01]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92d028bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 13)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8b470bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential([\n",
    "  Dense(256, activation='relu', input_shape=(13,)),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f8578cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a keras model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a61ffc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0954 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0138s). Check your callbacks.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1048 - accuracy: 0.3950\n",
      "Epoch 2/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0855 - accuracy: 0.3950\n",
      "Epoch 3/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0803 - accuracy: 0.3950\n",
      "Epoch 4/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0776 - accuracy: 0.3950\n",
      "Epoch 5/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0740 - accuracy: 0.3950\n",
      "Epoch 6/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0707 - accuracy: 0.3950\n",
      "Epoch 7/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0629 - accuracy: 0.3950\n",
      "Epoch 8/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0609 - accuracy: 0.4118\n",
      "Epoch 9/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0553 - accuracy: 0.5714\n",
      "Epoch 10/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0458 - accuracy: 0.5546\n",
      "Epoch 11/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0385 - accuracy: 0.4034\n",
      "Epoch 12/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0303 - accuracy: 0.4706\n",
      "Epoch 13/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0195 - accuracy: 0.6303\n",
      "Epoch 14/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0078 - accuracy: 0.6303\n",
      "Epoch 15/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9973 - accuracy: 0.6303\n",
      "Epoch 16/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9811 - accuracy: 0.6387\n",
      "Epoch 17/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9655 - accuracy: 0.6218\n",
      "Epoch 18/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9497 - accuracy: 0.6218\n",
      "Epoch 19/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9304 - accuracy: 0.6218\n",
      "Epoch 20/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9156 - accuracy: 0.6218\n",
      "Epoch 21/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8922 - accuracy: 0.6218\n",
      "Epoch 22/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8806 - accuracy: 0.6218\n",
      "Epoch 23/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8610 - accuracy: 0.6218\n",
      "Epoch 24/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8429 - accuracy: 0.6134\n",
      "Epoch 25/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8267 - accuracy: 0.6218\n",
      "Epoch 26/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8036 - accuracy: 0.6303\n",
      "Epoch 27/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7878 - accuracy: 0.6303\n",
      "Epoch 28/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7764 - accuracy: 0.6218\n",
      "Epoch 29/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7610 - accuracy: 0.6218\n",
      "Epoch 30/45\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7599 - accuracy: 0.62 - 0s 2ms/step - loss: 0.7514 - accuracy: 0.6218\n",
      "Epoch 31/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7412 - accuracy: 0.6555\n",
      "Epoch 32/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.6303\n",
      "Epoch 33/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7196 - accuracy: 0.6387\n",
      "Epoch 34/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7159 - accuracy: 0.6218\n",
      "Epoch 35/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7191 - accuracy: 0.6387\n",
      "Epoch 36/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.6807\n",
      "Epoch 37/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.6891\n",
      "Epoch 38/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.6303\n",
      "Epoch 39/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.6555\n",
      "Epoch 40/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.7059\n",
      "Epoch 41/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6764 - accuracy: 0.6639\n",
      "Epoch 42/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6717 - accuracy: 0.6387\n",
      "Epoch 43/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6693 - accuracy: 0.6975\n",
      "Epoch 44/45\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6681 - accuracy: 0.6639\n",
      "Epoch 45/45\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.6807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d760a87e20>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# education\n",
    "# %%time\n",
    "model.fit(X_train, \n",
    "          to_categorical(y_train), \n",
    "          epochs=45, \n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9ced90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step - loss: 0.5938 - accuracy: 0.6780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5938476324081421, 0.6779661178588867]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "  X_test,\n",
    "  to_categorical(y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e89f905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict \n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a453961e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 2, 2, 0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 1, 0, 1,\n",
       "       2, 1, 1, 2, 1, 2, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 2, 0, 1, 1, 2,\n",
       "       1, 0, 2, 1, 1, 0, 1, 0, 0, 2, 1, 0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b5f1c5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        20\n",
      "           1       0.64      0.67      0.65        24\n",
      "           2       0.36      0.27      0.31        15\n",
      "\n",
      "    accuracy                           0.68        59\n",
      "   macro avg       0.62      0.64      0.63        59\n",
      "weighted avg       0.65      0.68      0.66        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, np.argmax(predictions, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aad79720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[36  3]\n",
      "  [ 0 20]]\n",
      "\n",
      " [[26  9]\n",
      "  [ 8 16]]\n",
      "\n",
      " [[37  7]\n",
      "  [11  4]]]\n"
     ]
    }
   ],
   "source": [
    "print(multilabel_confusion_matrix(y_test, np.argmax(predictions, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e569837f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db34c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(13,)))\n",
    "\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=[1e-0, 1e-1, 1e-2, 1e-3, 1e-4])),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "794caf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir5',\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d16bebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 00s]\n",
      "accuracy: 0.6386554837226868\n",
      "\n",
      "Best accuracy So Far: 0.6386554837226868\n",
      "Total elapsed time: 00h 00m 22s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in my_dir5\\intro_to_kt\n",
      "Showing 10 best trials\n",
      "Objective(name='accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 192\n",
      "learning_rate: 0.1\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.6386554837226868\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 480\n",
      "learning_rate: 0.01\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: d175b6053b8e06a0b8f6412c336912b4\n",
      "Score: 0.6302521228790283\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 288\n",
      "learning_rate: 0.1\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 419e01e49b639dd6261f333ac6394632\n",
      "Score: 0.5798319578170776\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 480\n",
      "learning_rate: 0.01\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.4957983195781708\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 160\n",
      "learning_rate: 0.001\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: e6af76bdcd3b490fd6467dca1bc4fd6f\n",
      "Score: 0.48739495873451233\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 160\n",
      "learning_rate: 0.001\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.462184876203537\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 320\n",
      "learning_rate: 0.001\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.45378151535987854\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 192\n",
      "learning_rate: 0.01\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.45378151535987854\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 288\n",
      "learning_rate: 0.1\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: d27f11d9d6833eeee674253edf36050c\n",
      "Score: 0.4453781545162201\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 256\n",
      "learning_rate: 1.0\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.4285714328289032\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "tuner.search(X_train, y_train)\n",
    "\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "56748e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 192 and the optimal learning rate for the optimizer\n",
      "is 0.1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f9ea9ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.7398 - accuracy: 0.3368 - val_loss: 1.2049 - val_accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1987 - accuracy: 0.3474 - val_loss: 1.1568 - val_accuracy: 0.6250\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1088 - accuracy: 0.4421 - val_loss: 1.0684 - val_accuracy: 0.4583\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0813 - accuracy: 0.3789 - val_loss: 1.0315 - val_accuracy: 0.4583\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0588 - accuracy: 0.3789 - val_loss: 1.0163 - val_accuracy: 0.4583\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0239 - accuracy: 0.3789 - val_loss: 0.9670 - val_accuracy: 0.5417\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9818 - accuracy: 0.5895 - val_loss: 0.9507 - val_accuracy: 0.6250\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9399 - accuracy: 0.6316 - val_loss: 0.8766 - val_accuracy: 0.6667\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8955 - accuracy: 0.6211 - val_loss: 0.8762 - val_accuracy: 0.6250\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8469 - accuracy: 0.6316 - val_loss: 0.8070 - val_accuracy: 0.6250\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7970 - accuracy: 0.6526 - val_loss: 0.7987 - val_accuracy: 0.5833\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7758 - accuracy: 0.6000 - val_loss: 0.7370 - val_accuracy: 0.6250\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7705 - accuracy: 0.6737 - val_loss: 0.7608 - val_accuracy: 0.5833\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7176 - accuracy: 0.6211 - val_loss: 0.7290 - val_accuracy: 0.5833\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6866 - accuracy: 0.6421 - val_loss: 0.6920 - val_accuracy: 0.7083\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6991 - accuracy: 0.6632 - val_loss: 0.7134 - val_accuracy: 0.6250\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.6211 - val_loss: 0.6794 - val_accuracy: 0.6667\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6602 - accuracy: 0.6842 - val_loss: 0.6877 - val_accuracy: 0.6667\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7218 - accuracy: 0.6421 - val_loss: 0.6667 - val_accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6493 - accuracy: 0.7158 - val_loss: 0.6638 - val_accuracy: 0.7083\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6528 - accuracy: 0.6947 - val_loss: 0.6989 - val_accuracy: 0.6250\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6415 - accuracy: 0.6211 - val_loss: 0.6612 - val_accuracy: 0.6667\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6412 - accuracy: 0.6842 - val_loss: 0.6601 - val_accuracy: 0.6667\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6487 - accuracy: 0.6842 - val_loss: 0.6859 - val_accuracy: 0.6250\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6440 - accuracy: 0.6526 - val_loss: 0.6914 - val_accuracy: 0.6667\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6614 - accuracy: 0.6316 - val_loss: 0.6652 - val_accuracy: 0.7083\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6549 - accuracy: 0.6842 - val_loss: 0.6514 - val_accuracy: 0.6667\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6132 - accuracy: 0.6526 - val_loss: 0.7370 - val_accuracy: 0.5417\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6641 - accuracy: 0.6632 - val_loss: 0.6496 - val_accuracy: 0.6250\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6617 - accuracy: 0.6526 - val_loss: 0.6509 - val_accuracy: 0.6667\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6533 - accuracy: 0.7053 - val_loss: 0.6563 - val_accuracy: 0.6667\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6222 - accuracy: 0.6526 - val_loss: 0.6912 - val_accuracy: 0.6250\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6283 - accuracy: 0.6421 - val_loss: 0.6533 - val_accuracy: 0.7083\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6494 - accuracy: 0.6842 - val_loss: 0.6523 - val_accuracy: 0.6667\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6457 - accuracy: 0.6316 - val_loss: 0.7355 - val_accuracy: 0.5417\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6662 - accuracy: 0.7053 - val_loss: 0.6390 - val_accuracy: 0.7083\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6444 - accuracy: 0.6842 - val_loss: 0.6779 - val_accuracy: 0.6250\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6274 - accuracy: 0.6211 - val_loss: 0.6631 - val_accuracy: 0.6667\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6206 - accuracy: 0.6632 - val_loss: 0.6469 - val_accuracy: 0.7083\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6441 - accuracy: 0.7053 - val_loss: 0.6498 - val_accuracy: 0.6250\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6200 - accuracy: 0.6316 - val_loss: 0.6948 - val_accuracy: 0.6250\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6517 - accuracy: 0.6842 - val_loss: 0.6252 - val_accuracy: 0.6667\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6700 - accuracy: 0.6421 - val_loss: 0.6816 - val_accuracy: 0.6250\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6116 - accuracy: 0.6947 - val_loss: 0.6339 - val_accuracy: 0.7083\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6279 - accuracy: 0.7368 - val_loss: 0.6494 - val_accuracy: 0.6667\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6156 - accuracy: 0.6526 - val_loss: 0.6507 - val_accuracy: 0.6667\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6164 - accuracy: 0.6947 - val_loss: 0.6184 - val_accuracy: 0.6667\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6043 - accuracy: 0.6947 - val_loss: 0.6437 - val_accuracy: 0.6667\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6174 - accuracy: 0.6316 - val_loss: 0.6383 - val_accuracy: 0.6667\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5971 - accuracy: 0.6842 - val_loss: 0.6123 - val_accuracy: 0.7083\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af0b4f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 15\n"
     ]
    }
   ],
   "source": [
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8ee8f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ee48e067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.5311 - accuracy: 0.3158 - val_loss: 1.0575 - val_accuracy: 0.4583\n",
      "Epoch 2/15\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.1299 - accuracy: 0.3789 - val_loss: 1.0563 - val_accuracy: 0.4583\n",
      "Epoch 3/15\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.1055 - accuracy: 0.3789 - val_loss: 1.0612 - val_accuracy: 0.4583\n",
      "Epoch 4/15\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0854 - accuracy: 0.3789 - val_loss: 1.0817 - val_accuracy: 0.4583\n",
      "Epoch 5/15\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0870 - accuracy: 0.4105 - val_loss: 1.0906 - val_accuracy: 0.4583\n",
      "Epoch 6/15\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0848 - accuracy: 0.4421 - val_loss: 1.0899 - val_accuracy: 0.4167\n",
      "Epoch 7/15\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0849 - accuracy: 0.4632 - val_loss: 1.0707 - val_accuracy: 0.5000\n",
      "Epoch 8/15\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0671 - accuracy: 0.4105 - val_loss: 1.0473 - val_accuracy: 0.5000\n",
      "Epoch 9/15\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0514 - accuracy: 0.5368 - val_loss: 1.0268 - val_accuracy: 0.6667\n",
      "Epoch 10/15\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0251 - accuracy: 0.5789 - val_loss: 0.9845 - val_accuracy: 0.6667\n",
      "Epoch 11/15\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9933 - accuracy: 0.6211 - val_loss: 0.9529 - val_accuracy: 0.6250\n",
      "Epoch 12/15\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9590 - accuracy: 0.6211 - val_loss: 0.9097 - val_accuracy: 0.6667\n",
      "Epoch 13/15\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9185 - accuracy: 0.6632 - val_loss: 0.8834 - val_accuracy: 0.6250\n",
      "Epoch 14/15\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8817 - accuracy: 0.6421 - val_loss: 0.8305 - val_accuracy: 0.6250\n",
      "Epoch 15/15\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8521 - accuracy: 0.6421 - val_loss: 0.8096 - val_accuracy: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d761f52370>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain the model\n",
    "hypermodel.fit(X_train, y_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8aec8bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 999us/step - loss: 0.7843 - accuracy: 0.7458\n",
      "[test loss, test accuracy]: [0.7842600345611572, 0.7457627058029175]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(X_test, y_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d025ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict \n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f3bd54e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 0, 1, 0, 1, 2, 2, 0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 1, 0, 1,\n",
       "       2, 1, 1, 2, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 2, 1, 2, 2, 0, 1, 1, 2,\n",
       "       1, 0, 2, 1, 1, 0, 1, 0, 0, 2, 1, 2, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7a7f5d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        20\n",
      "           1       0.67      0.67      0.67        24\n",
      "           2       0.40      0.40      0.40        15\n",
      "\n",
      "    accuracy                           0.69        59\n",
      "   macro avg       0.67      0.67      0.67        59\n",
      "weighted avg       0.69      0.69      0.69        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, np.argmax(predictions, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e37eab7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[38  1]\n",
      "  [ 1 19]]\n",
      "\n",
      " [[27  8]\n",
      "  [ 8 16]]\n",
      "\n",
      " [[35  9]\n",
      "  [ 9  6]]]\n"
     ]
    }
   ],
   "source": [
    "print(multilabel_confusion_matrix(y_test, np.argmax(predictions, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71fcba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
